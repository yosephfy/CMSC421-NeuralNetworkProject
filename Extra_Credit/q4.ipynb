{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `CNNModel` Class Documentation\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "The `CNNModel` class defines a Convolutional Neural Network (CNN) architecture suitable for `IMAGE` classification tasks. It inherits from the `nn.Module` of PyTorch, providing the foundational structure to build, train, and evaluate deep learning models in PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "### Attributes:\n",
    "- **conv**: The convolutional layers of the CNN.\n",
    "- **fc**: A fully connected layer used for classification (not yet defined in the provided code).\n",
    "\n",
    "---\n",
    "\n",
    "### Methods:\n",
    "\n",
    "#### `__init__(self, args)`\n",
    "- **Purpose**: Initializes the CNN model.\n",
    "- **Parameters**: \n",
    "  - **args**: A set of arguments containing hyperparameters and configurations for the CNN.\n",
    "- **Description**: \n",
    "  - Constructs the convolutional layers using the provided arguments. The detailed architecture has to be filled in under the `TODO` comment.\n",
    "\n",
    "---\n",
    "\n",
    "#### `forward(self, x)`\n",
    "- **Purpose**: Defines the forward pass of the CNN.\n",
    "- **Parameters**: \n",
    "  - **x**: An input tensor with shape (batch_size, channels, height, width), typically representing a batch of images.\n",
    "- **Returns**: \n",
    "  - An output tensor (not yet defined in the code) with shape (batch_size, num_classes), representing the model's predictions for each image in the batch.\n",
    "- **Description**: \n",
    "  - Processes the input tensor through the CNN's layers to produce a prediction for each image. The exact forward pass operations need to be defined under the `TODO` comment.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This class provides a template for a CNN model suitable for MNIST classification. Several components, including the exact architecture of the convolutional layers and the forward pass operations, are indicated with `TODO` comments, suggesting that these parts need further implementation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------#\n",
    "#--------- THIS CELL NEEDS TO BE EDITED!! WE HAVE INCLUDED TODO COMMENT(S) ----------# \n",
    "#--------------------------- TO GUIDE YOUR IMPLEMENTATION ---------------------------#\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "\"\"\"\n",
    "define modules of model\n",
    "\"\"\"\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network (CNN) image classification.\n",
    "    \n",
    "    Attributes:\n",
    "        conv: Convolutional layers.\n",
    "        fc: Fully connected layer for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the CNN model with given arguments.\n",
    "        \n",
    "        Args:\n",
    "            args: Arguments containing hyperparameters.\n",
    "        \"\"\"\n",
    "        # TODO:\n",
    "        # - Define the architecture for the convolutional layers using nn.Sequential.\n",
    "        # - Utilize the hyperparameters given by the `args` argument (like the number of channels, kernel size, etc.).\n",
    "        # - Add the necessary convolutional layers (`nn.Conv2d`), activation functions (`nn.ReLU`, etc.), and pooling layers (`nn.MaxPool2d`, etc.) as needed.\n",
    "        # - Ensure the depth and the sizes of the feature maps after each layer align with the desired architecture.\n",
    "        # Convolutional Layers\n",
    "        self.conv = nn.Sequential(\n",
    "            # use the arguments to build your CNN Model Here\n",
    "            )\n",
    "        \n",
    "        # TODO:\n",
    "        # - Define the fully connected (dense) layers for the network.\n",
    "        # - Determine the input dimension to the first fully connected layer. This should be the flattened size of the feature map produced by the last convolutional layer.\n",
    "        # - Define linear layers (`nn.Linear`) based on the desired number of neurons in the hidden layers and the number of output classes.\n",
    "        # - Remember to add activation functions (`nn.ReLU`, etc.) in between these linear layers.\n",
    "        # - Optionally, consider adding dropout layers (`nn.Dropout`) for regularization if needed.\n",
    "        # Fully Connected Layers\n",
    "        self.fc = None\n",
    "\n",
    "    # Feed features to the model\n",
    "    def forward(self, x):  # default\n",
    "        \"\"\"\n",
    "        Forward pass of the CNN.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, channels, height, width)\n",
    "            \n",
    "        Returns:\n",
    "            result: Output tensor of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # TODO:\n",
    "        # - Pass the input tensor `x` through the convolutional layers defined in `self.conv`.\n",
    "        # - Flatten the resulting feature map to make it suitable for the fully connected layers.\n",
    "        # - Pass the flattened tensor through the fully connected layers (`self.fc`).\n",
    "        # - Ensure the final output tensor has a shape compatible with the expected number of classes for the classification task.\n",
    "        # - Consider using an activation function like softmax if needed at the output (especially if the loss function you're planning to use requires it).\n",
    "\n",
    "        x_out = None        \n",
    "        return x_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------#\n",
    "#--------- THIS CELL CAN TO BE EDITED!! WE HAVE INCLUDED TODO COMMENT(S) ----------# \n",
    "#--------------------------- TO GUIDE YOUR IMPLEMENTATION ---------------------------#\n",
    "#------------------------------------------------------------------------------------#\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import argparse\n",
    "import os.path\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from torchsummary import summary\n",
    "# from utils import str2bool  # Utility function for argument parsing\n",
    "\n",
    "\n",
    "def load_data(DATA_PATH, batch_size):\n",
    "    print(f\"data_path: {DATA_PATH}\")\n",
    "\n",
    "    # Define transformations\n",
    "    train_trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    test_trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # Create train and test datasets\n",
    "    train_dataset = ImageFolder(root=f\"{DATA_PATH}train\", transform=train_trans)\n",
    "    test_dataset = ImageFolder(root=f\"{DATA_PATH}test\", transform=test_trans)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def compute_accuracy(y_pred, y_batch):\n",
    "    accy = (y_pred == y_batch).sum().item() / len(y_batch)\n",
    "    return accy\n",
    "\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_labels in val_loader:\n",
    "            x_batch, y_labels = x_batch.to(device), y_labels.to(device)\n",
    "            output_y = model(x_batch)\n",
    "            loss = nn.CrossEntropyLoss()(output_y, y_labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(output_y, 1)\n",
    "            val_accuracy += (preds == y_labels).float().mean()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_labels.cpu().numpy())\n",
    "\n",
    "    confusion = confusion_matrix(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return val_loss/len(val_loader), val_accuracy/len(val_loader), confusion, precision, recall, f1\n",
    "\n",
    "def print_model_size(model):\n",
    "    summary(model, (1, 28, 28)) \n",
    "\n",
    "def adjust_learning_rate(learning_rate, optimizer, epoch, decay):\n",
    "    lr = learning_rate\n",
    "    if epoch > 5:\n",
    "        lr = 0.001\n",
    "    if epoch >= 10:\n",
    "        lr = 0.0001\n",
    "    if epoch > 20:\n",
    "        lr = 0.00001\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "\n",
    "def train_one_epoch(model, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    for batch_id, (x_batch, y_labels) in tqdm(enumerate(train_loader), desc=\"Training\", leave=False):  \n",
    "        x_batch, y_labels = Variable(x_batch).to(device), Variable(y_labels).to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        output_y = model(x_batch)\n",
    "        loss = nn.CrossEntropyLoss()(output_y, y_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, y_pred = torch.max(output_y.data, 1)\n",
    "        accy = compute_accuracy(y_pred, y_labels)\n",
    "\n",
    "        # Here, you can add code to log or print the loss and accuracy if you want\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_accy = 0\n",
    "    for batch_id, (x_batch, y_labels) in tqdm(enumerate(test_loader), desc=\"Testing\", leave=False):  \n",
    "        x_batch, y_labels = Variable(x_batch).to(device), Variable(y_labels).to(device)\n",
    "        output_y = model(x_batch)\n",
    "        _, y_pred = torch.max(output_y.data, 1)\n",
    "        accy = compute_accuracy(y_pred, y_labels)\n",
    "        total_accy += accy\n",
    "    return total_accy / len(test_loader)\n",
    "    \n",
    "\n",
    "def main():\n",
    "\n",
    "    \n",
    "    # TODO These args are for use in main and also for building your network. The current values are defaults and can be edited to suite your needs!\n",
    "    \"\"\"\n",
    "    args:\n",
    "    \"-mode\", dest=\"mode\", type=str, default='train', help=\"train or test\"\n",
    "    \"-num_epochs\", dest=\"num_epoches\", type=int, default=40, help=\"num of epoches\"\n",
    "    \"-fc_hidden1\", dest=\"fc_hidden1\", type=int, default=100, help=\"dim of hidden neurons\"\n",
    "    \"-fc_hidden2\", dest=\"fc_hidden2\", type=int, default=100, help=\"dim of hidden neurons\"\n",
    "    \"-learning_rate\", dest =\"learning_rate\", type=float, default=0.001, help = \"learning rate\"\n",
    "    \"-decay\", dest =\"decay\", type=float, default=0.5, help = \"learning rate\"\n",
    "    \"-batch_size\", dest=\"batch_size\", type=int, default=100, help=\"batch size\"\n",
    "    \"-dropout\", dest =\"dropout\", type=float, default=0.4, help = \"dropout prob\"\n",
    "    \"-rotation\", dest=\"rotation\", type=int, default=10, help=\"image rotation\"\n",
    "    \"-load_checkpoint\", dest=\"load_checkpoint\", type=bool, default=True, help=\"true of false\"\n",
    "\n",
    "    \"-activation\", dest=\"activation\", type=str, default='relu', help=\"activation function\"\n",
    "    \"-channel_out1\", dest='channel_out1', type=int, default=64, help=\"number of channels\"\n",
    "    \"-channel_out2\", dest='channel_out2', type=int, default=64, help=\"number of channels\"\n",
    "    \"-k_size\", dest='k_size', type=int, default=4, help=\"size of filter\"\n",
    "    \"-pooling_size\", dest='pooling_size', type=int, default=2, help=\"size for max pooling\"\n",
    "    \"-stride\", dest='stride', type=int, default=1, help=\"stride for filter\"\n",
    "    \"-max_stride\", dest='max_stride', type=int, default=2, help=\"stride for max pooling\"\n",
    "    \"-ckp_path\", dest='ckp_path', type=str, default=\"checkpoint\", help=\"path of checkpoint\"\n",
    "    \"\"\"\n",
    "    args = argparse.Namespace(\n",
    "        mode='train',\n",
    "        num_epochs=3,\n",
    "        fc_hidden1=100,\n",
    "        fc_hidden2=100,\n",
    "        learning_rate=0.002,\n",
    "        decay=0.5,\n",
    "        batch_size=100,\n",
    "        dropout=0.4,\n",
    "        rotation=10,\n",
    "        load_checkpoint=False,\n",
    "        activation='relu',\n",
    "        channel_out1=64,\n",
    "        channel_out2=64,\n",
    "        stride=1,\n",
    "        max_stride=2,\n",
    "        ckp_path='checkpoint',\n",
    "        k_size=4,\n",
    "        pooling_size=2,\n",
    "        )\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    use_mps = torch.backends.mps.is_available()\n",
    "    device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "    print(f\"device: {device}\")\n",
    "\n",
    "    train_loader, test_loader = load_data(\"../New_Code/data/\", args.batch_size)\n",
    "\n",
    "    model = CNNModel(args=args).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        adjust_learning_rate(args.learning_rate, optimizer, epoch, args.decay)\n",
    "        train_one_epoch(model, optimizer, train_loader, device)\n",
    "        test_accuracy = test_model(model, test_loader, device)\n",
    "        print(f\"Epoch {epoch+1}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "        # Optionally, save model checkpoint here\n",
    "\n",
    "    print(\"Training Complete!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    end_time = time.time()\n",
    "    print(f\"Running time: {(end_time - start_time) / 60.0:.2f} mins\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
